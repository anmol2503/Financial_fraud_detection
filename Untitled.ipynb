{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48c60afa-3e21-4c0e-995e-d22e8631c61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- step: integer (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- nameOrig: string (nullable = true)\n",
      " |-- oldbalanceOrg: double (nullable = true)\n",
      " |-- newbalanceOrig: double (nullable = true)\n",
      " |-- nameDest: string (nullable = true)\n",
      " |-- oldbalanceDest: double (nullable = true)\n",
      " |-- newbalanceDest: double (nullable = true)\n",
      " |-- isFraud: integer (nullable = true)\n",
      " |-- isFlaggedFraud: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Fraud Detection\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load the dataset\n",
    "df = spark.read.csv('Synthetic_Financial_datasets_log.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Show the schema\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96ab43f0-7d64-48a7-a5be-889c0ee56049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|            features|isFraud|\n",
      "+--------------------+-------+\n",
      "|[1.0,9839.64,1701...|      0|\n",
      "|[1.0,1864.28,2124...|      0|\n",
      "|[1.0,181.0,181.0,...|      1|\n",
      "|[1.0,181.0,181.0,...|      1|\n",
      "|[1.0,11668.14,415...|      0|\n",
      "|[1.0,7817.71,5386...|      0|\n",
      "|[1.0,7107.77,1831...|      0|\n",
      "|[1.0,7861.64,1760...|      0|\n",
      "|[1.0,4024.36,2671...|      0|\n",
      "|[1.0,5337.77,4172...|      0|\n",
      "|[1.0,9644.94,4465...|      0|\n",
      "|[1.0,3099.97,2077...|      0|\n",
      "|[1.0,2560.74,5070...|      0|\n",
      "|[1.0,11633.76,101...|      0|\n",
      "|[1.0,4098.78,5032...|      0|\n",
      "|[1.0,229133.94,15...|      0|\n",
      "|[1.0,1563.82,450....|      0|\n",
      "|[1.0,1157.86,2115...|      0|\n",
      "|[1.0,671.64,15123...|      0|\n",
      "|[1.0,215310.3,705...|      0|\n",
      "+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Index the categorical column 'type'\n",
    "indexer = StringIndexer(inputCol='type', outputCol='type_index')\n",
    "\n",
    "# Select features for the model (you can adjust this based on your needs)\n",
    "feature_cols = ['step', 'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest', 'type_index']\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline(stages=[indexer, assembler])\n",
    "df_transformed = pipeline.fit(df).transform(df)\n",
    "\n",
    "# Show transformed data\n",
    "df_transformed.select('features', 'isFraud').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb72d0c9-b31e-4edc-ae50-2a35712de301",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = df_transformed.randomSplit([0.8, 0.2], seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a675272b-973d-4adc-b2f3-f1775caec3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Get counts\n",
    "count_1 = df_transformed.filter(col(\"isFraud\") == 1).count()\n",
    "count_0 = df_transformed.filter(col(\"isFraud\") == 0).count()\n",
    "\n",
    "# Oversample the minority class\n",
    "fraud_data = df_transformed.filter(col(\"isFraud\") == 1)\n",
    "non_fraud_data = df_transformed.filter(col(\"isFraud\") == 0)\n",
    "\n",
    "# Randomly sample the majority class to match the minority class\n",
    "non_fraud_data_oversampled = non_fraud_data.sample(False, count_1 / count_0, seed=42)\n",
    "\n",
    "# Combine the two datasets\n",
    "balanced_data = fraud_data.union(non_fraud_data_oversampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34bcf402-8796-4451-978b-ea2d28ca39f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(labelCol='isFraud', featuresCol='features', numTrees=100)\n",
    "model = rf.fit(balanced_data)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"/data/fraud_detection_model_V2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52ccfa49-cfb8-41ef-a80e-216a48abc42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+----------+\n",
      "|            features|isFraud|prediction|\n",
      "+--------------------+-------+----------+\n",
      "|[1.0,783.31,81503...|      0|       0.0|\n",
      "|[1.0,1271.77,6973...|      0|       0.0|\n",
      "|[1.0,2643.45,6434...|      0|       0.0|\n",
      "|[1.0,6284.18,7858...|      0|       0.0|\n",
      "|[1.0,8679.13,7087...|      0|       0.0|\n",
      "|[1.0,9577.45,5198...|      0|       0.0|\n",
      "|[1.0,12336.48,731...|      0|       0.0|\n",
      "|[1.0,16236.25,826...|      0|       0.0|\n",
      "|[1.0,19872.97,356...|      0|       0.0|\n",
      "|[1.0,20490.81,596...|      0|       0.0|\n",
      "|[1.0,21255.8,3113...|      0|       0.0|\n",
      "|[1.0,21898.97,722...|      0|       0.0|\n",
      "|[1.0,22765.47,969...|      0|       0.0|\n",
      "|[1.0,24936.34,482...|      0|       0.0|\n",
      "|[1.0,27948.65,118...|      0|       0.0|\n",
      "|[1.0,31646.31,584...|      0|       0.0|\n",
      "|[1.0,34918.59,433...|      0|       0.0|\n",
      "|[1.0,44655.46,445...|      0|       0.0|\n",
      "|[1.0,49031.62,454...|      0|       0.0|\n",
      "|[1.0,51284.87,413...|      0|       0.0|\n",
      "+--------------------+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Accuracy: 0.9554292600952349\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test_data)\n",
    "predictions.select('features', 'isFraud', 'prediction').show()\n",
    "\n",
    "# Evaluate the model\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='isFraud', predictionCol='prediction', metricName='accuracy')\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c351a88b-e5c1-42cb-b5db-6c32521eb3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Not Fraud\n"
     ]
    }
   ],
   "source": [
    "def predict_fraud(input_data):\n",
    "    # Create a DataFrame from the input\n",
    "    input_df = spark.createDataFrame([input_data], schema=['step', 'type', 'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest'])\n",
    "\n",
    "    # Transform the input\n",
    "    input_transformed = pipeline.fit(input_df).transform(input_df)\n",
    "    \n",
    "    # Make predictions\n",
    "    prediction = model.transform(input_transformed)\n",
    "    \n",
    "    return prediction.select('prediction').collect()[0][0]\n",
    "\n",
    "# Example usage\n",
    "user_input = [1, 'Debit', 5000, 9000, 4000, 0, 5000]  # Example input\n",
    "result = predict_fraud(user_input)\n",
    "print(\"Prediction:\", \"Fraud\" if result == 1 else \"Not Fraud\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc8630a-a62c-4e51-afdf-f0e11d57016a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
